{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c8cfb00-e77b-4d4c-8017-c2a3b7178fc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Saliency Calculation using python\n",
    "\n",
    "In this notebook we reimplement the saliency calculation as presented in [1].\n",
    "\n",
    "During this course we will make 5 different implementations in order to explore different approaches and compare them in terms of simplicity and excecution time. The implementation go as follows:\n",
    "\n",
    "1. Python and Numpy *(only for vector operations and eigen decomposition)*.\n",
    "2. Numba and Numpy *(only for vector operations and eigen decomposition)*.\n",
    "3. Numpy \n",
    "4. PyTorch\n",
    "5. PyTorch on GPU\n",
    "\n",
    "\n",
    "[1] G. Arvanitis, A. S. Lalos and K. Moustakas, \"Robust and Fast 3-D Saliency Mapping for Industrial Modeling Applications,\" in IEEE Transactions on Industrial Informatics, vol. 17, no. 2, pp. 1307-1317, Feb. 2021, doi: 10.1109/TII.2020.3003455."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f0af23-2195-4411-b697-f98269d46eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# library imports and initialization\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "data_path = './resources/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dabf1568-551d-4612-89a0-b30bfd8bf7fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579c0a35-a10a-4827-a50d-8a05eef67d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triangle mesh with: 33910 vertices\n"
     ]
    }
   ],
   "source": [
    "# select the mesh you want to use\n",
    "filename = '6.obj' \n",
    "\n",
    "# load the mesh using open3d\n",
    "mesh = o3d.io.read_triangle_mesh(data_path + filename)\n",
    "print(f\"Triangle mesh with: {len(np.asarray(mesh.vertices))} vertices\")\n",
    "\n",
    "# Compute the vertex normals \n",
    "mesh.compute_vertex_normals()\n",
    "\n",
    "# NOTE: draw_geometries will run a visualizer outside the jupyter notebook environment\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fff65f95-0dd7-46e7-8b23-f04418fbbb9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Neighbor Search\n",
    "\n",
    "The first thing to do when calculating saliency is to find the k nearest neighbors for each vertex of the mesh.\n",
    "\n",
    "Open3d provides a structure to build a KDTree, that can be created directly from an open3d **Geometry**, such as a point cloud or a triangle mesh. \n",
    "\n",
    "So the steps we will follow are:\n",
    "1. Create a KDTree Structure from the 3D mesh\n",
    "2. Select a query point, find its KNN using the KDTree and visualize them\n",
    "3. For each vertex of the mesh find its K nearest neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02666c77-5c39-4819-b8b8-525bf7f3ca05",
   "metadata": {},
   "source": [
    "### 1. Create the KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b8c86c3-a4e9-42f1-98be-9ac5bda17cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tree = o3d.geometry.KDTreeFlann(mesh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a505fef8-3ce0-4b3f-92e4-0bb0a2c2cd1a",
   "metadata": {},
   "source": [
    "### 2. Find and visualize the neighbor of a query point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51837d1b-0c81-4c93-aeaa-4d9cd9eec63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " IntVector[12350, 12564, 12132, 12342, 12351, 12131, 12573, 12565, 12133, 12784, 11911, 12124, 12574, 12785, 11912, 12343, 12352, 11910, 12794, 13008, 12786, 11913, 12909, 12566, 12134, 11686, 12125, 11685, 12575, 11904, 12795, 13009, 11687, 12344, 12353, 11684, 13018, 13129, 12787, 11914, 13226, 13010, 11455, 11905, 11688, 12567, 11456, 12797, 12135, 12126])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx = 12350\n",
    "k = 50\n",
    "\n",
    "# use the KDTree to find the knns\n",
    "[k, idx, _] = knn_tree.search_knn_vector_3d(mesh.vertices[query_idx], k)\n",
    "k, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdea233-f999-4cf3-97cd-39187cba34bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a point cloud using the selected points\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "selected = vertices[idx]\n",
    "\n",
    "pcd = o3d.utility.Vector3dVector(selected)\n",
    "pcd = o3d.geometry.PointCloud(pcd)\n",
    "pcd.paint_uniform_color((1.0, 0.0, 0.0))\n",
    "\n",
    "# NOTE: Use +/- to increase/decrease point size\n",
    "o3d.visualization.draw_geometries([mesh, pcd])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "344da7ad-c87d-47b9-a90e-e0eda9af05a4",
   "metadata": {},
   "source": [
    "### 3. For each vertex of the mesh find its knns\n",
    "\n",
    "As of open3d version 0.17.0 I did not find a way to run a knn search for all the vertices of the mesh at once. \n",
    "So we will have to use a for loop to parse all the vertices and find the knns for each one of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316d7ffc-a6ac-48ca-ab4e-b990d8a107d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=5\n",
    "knns=[]\n",
    "vertices = np.asarray(mesh.vertices)\n",
    "\n",
    "for v in vertices:\n",
    "\n",
    "    [_, ids, _] = knn_tree.search_knn_vector_3d(v, k)\n",
    "    knns.append(ids)\n",
    "\n",
    "# Create a np.array to store this information\n",
    "knns = np.stack(knns)\n",
    "knns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7c251f-6e58-4ede-9965-adcc0e8bfd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, 12555,    18],\n",
       "       [    1, 12555,    37,     0, 12556],\n",
       "       [    2,    33,    37,     0,    18],\n",
       "       [    3,     5,    27,     4, 10973],\n",
       "       [    4,     5, 10975,     3, 10972],\n",
       "       [    5,     4,     3,    20, 10972],\n",
       "       [    6,    10,     9,     7,     8],\n",
       "       [    7,    39,    21,    19,     8],\n",
       "       [    8,    31,     9,     7,    19],\n",
       "       [    9,     8,    28,    29,    31]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knns[:10, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e525244e-ca98-40a0-857e-6d0643640817",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function \n",
    "Create a function that will receive a o3d mesh with **N** vertices and the desired number of neighbors **k** as input\n",
    "and return a np.array with shape [N, k] containing the indices of the neighboring vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2272b704-5803-4211-a00c-b1f01839fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search(mesh, k):\n",
    "    # create the kdTree\n",
    "    knn_tree = o3d.geometry.KDTreeFlann(mesh)\n",
    "\n",
    "    # list to store the neighbors\n",
    "    knns=[]\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    \n",
    "    for v in vertices:\n",
    "    \n",
    "        [kt, ids, _] = knn_tree.search_knn_vector_3d(v, k)\n",
    "        knns.append(ids)\n",
    "    \n",
    "    # Create a np.array to store this information\n",
    "    knns = np.stack(knns)\n",
    "\n",
    "    return knns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c98d91d-b0fe-4da3-82b8-8a339d1e1221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n10 _=knn_search(mesh, 15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7eef373-a500-416a-ab9b-0691f71a2e4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python Saliency calculation\n",
    "\n",
    "We will start with a simple Saliency calculation using pure python and numpy. \n",
    "\n",
    "However, we set a limitation. Numpy will only be used to store the data and perform the eigen decomposition of the covariance matrix. \n",
    "\n",
    "\n",
    "The steps we will follow:\n",
    "1. Find the indexes of the neighbors for each point\n",
    "2. Get the normals of the neighbors to create the **N** matrix. Note that since we use a 3D mesh, we have access to the vertex normals.\n",
    "3. Calculate the covariance matrix for each vertex.\n",
    "4. Perform eigen decomposition and use the eigenvalus to compute the saliency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0889f66b-db1b-4f87-9453-8fe4700229ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normals = np.asarray(mesh.vertex_normals)\n",
    "normals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919e538c-28b8-4aed-adc7-0cde8ba2302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Find the indexes of the neighbors for each point\n",
    "k=15\n",
    "knns = knn_search(mesh, k)\n",
    "knns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8e6298-7e39-48a5-9c2b-b4dacc3fa7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 15, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Get the normals of the neighbors to create the N matrix. Note that since we use a 3D mesh, we have access to the vertex normals.\n",
    "N = normals[knns]\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bccf9c79-5c63-4dff-9b2a-bbb0fa6a45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "# dummy for loop\n",
    "saliency_vals = []\n",
    "\n",
    "# parse each vertex of the mesh and use the normals of the neighbor to compute the covariance matrix\n",
    "for n in N:\n",
    "\n",
    "    # 3. Calculate the covariance matrix for each vertex\n",
    "    \n",
    "    # n.shape = 15, 3\n",
    "    # cov = n.t(3, 15) x n(15, 3) --> cov(3, 3)\n",
    "    cov = np.dot(n.transpose(), n)\n",
    "\n",
    "    # 4. Perform eigen decomposition and use the eigenvalus to compute the saliency.\n",
    "    eigenvalues, _ = np.linalg.eig(cov)\n",
    "\n",
    "    eig1, eig2, eig3 = eigenvalues[0], eigenvalues[1], eigenvalues[2]\n",
    "    saliency = 1 / sqrt(eig1 * eig1 + eig2 * eig2 + eig3 * eig3)\n",
    "\n",
    "    saliency_vals.append(saliency)\n",
    "\n",
    "\n",
    "saliency = np.stack(saliency_vals)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2ac5cf7-0482-4bcc-90c0-947e3498306d",
   "metadata": {},
   "source": [
    "### Colorize the mesh with respect to the saliency values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b6acf92-8292-4366-b64f-8add6d3d4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize saliency values\n",
    "saliency_norm = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "\n",
    "color = np.zeros((len(saliency_vals), 3))\n",
    "color[:, 0] = saliency_norm\n",
    "\n",
    "mesh.vertex_colors = o3d.utility.Vector3dVector(color)\n",
    "\n",
    "o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37da89ef-d832-4848-83e8-4e51c7b9c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_saliency(mesh, saliency):\n",
    "    color = np.zeros((len(saliency), 3))\n",
    "    color[:, 0] = saliency\n",
    "    mesh.vertex_colors = o3d.utility.Vector3dVector(color)\n",
    "\n",
    "    o3d.visualization.draw_geometries([mesh])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a5a88cb-5b7d-4245-a703-d6c3b1b1e9fb",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62f07053-768e-4a43-9b4b-93eb3164a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will get the mesh normals and the knn matrix and calculate the saliency\n",
    "def saliency_python(normals, knns):\n",
    "    \n",
    "    N = normals[knns]\n",
    "\n",
    "    saliency_vals = np.zeros((normals.shape[0]))\n",
    "\n",
    "    # parse each vertex of the mesh and use the normals of the neighbor to compute the covariance matrix\n",
    "    for i, n in enumerate(N):\n",
    "            \n",
    "        # n.shape = 15, 3\n",
    "        # cov = n.t(3, 15) x n(15, 3) --> cov(3, 3)\n",
    "        cov = np.dot(n.transpose(), n)\n",
    "    \n",
    "        eigenvalues, _ = np.linalg.eig(cov)\n",
    "    \n",
    "        eig1, eig2, eig3 = eigenvalues[0], eigenvalues[1], eigenvalues[2]\n",
    "        saliency = 1 / sqrt(eig1 * eig1 + eig2 * eig2 + eig3 * eig3)\n",
    "    \n",
    "        saliency_vals[i] = saliency\n",
    "    \n",
    "    saliency_norm = (saliency_vals - saliency_vals.min()) / (saliency_vals.max() - saliency_vals.min())\n",
    "\n",
    "    return saliency_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53b46768-f87a-4f3e-a9c3-7f6ffb26fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 ms ± 6.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_python(normals, knns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba0baa09-200c-4ac4-8c41-15777575af34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Numba Saliency Calculation\n",
    "\n",
    "Numba uses a jit compiler to make the python code faster to excecute. \n",
    "\n",
    "The main constraint of numba is that is has to run only python and numpy related code and some options may still not be available. \n",
    "For example the advanced indexing $N = normals[knns]$ cannot be compiled with the jit compiler and has to be separated from the rest of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7c99016-262b-46a9-8fa2-c37fdd9715f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit(nopython=True)\n",
    "def saliency_numba_jit(N):\n",
    "    \n",
    "    saliency_vals = np.zeros((normals.shape[0]))\n",
    "\n",
    "    # parse each vertex of the mesh and use the normals of the neighbor to compute the covariance matrix\n",
    "    for i in range(len(N)):\n",
    "        \n",
    "        n = N[i]    \n",
    "        # n.shape = 15, 3\n",
    "        # cov = n.t(3, 15) x n(15, 3) --> cov(3, 3)\n",
    "        cov = np.dot(n.transpose(), n)\n",
    "    \n",
    "        eigenvalues, _ = np.linalg.eig(cov)\n",
    "        \n",
    "        eig1, eig2, eig3 = eigenvalues[0], eigenvalues[1], eigenvalues[2]\n",
    "        saliency = 1 / np.sqrt(eig1 * eig1 + eig2 * eig2 + eig3 * eig3)\n",
    "    \n",
    "        saliency_vals[i] = saliency\n",
    "    \n",
    "    return saliency_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a26fcccb-0a74-40f9-93bd-c6767745333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This advanced indexing cannot be compiled using numba\n",
    "N = normals[knns]\n",
    "saliency = saliency_numba_jit(N)\n",
    "saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "visualize_saliency(mesh, saliency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "103ada08-6c01-4874-b2e8-84911e04e5f1",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a886a869-f278-44d7-a094-f31b1ed8fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_numba(normals, knns):\n",
    "    N = normals[knns]\n",
    "    saliency = saliency_numba_jit(N)\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "286f5de0-e10a-49c4-b189-4647665d07ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.5 ms ± 610 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_numba(normals, knns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "573925ed-1b70-4377-ad5d-f866313326e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Numpy saliency calculation\n",
    "\n",
    "We will try to remove the outter loop all together and replace in with matrix operations.\n",
    "\n",
    "Before we created the *N* matrix, with shape [N, k, 3], where N is the number of vertices and k the number of neighbors. \n",
    "Then we iterated through a for loop and did a matrix multiplication for each vertex. \n",
    "Now, we will try to do all these multiplications all together.\n",
    "\n",
    "Our goal is to create a covariance matrix for each vertex. To store this matrix we will need a np.array of shape [N, 3, 3].\n",
    "\n",
    "We will explore two ways of doing this, one with matrix multiplication and one using einsum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc2727c-3766-4dd0-93ec-d79571c34e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 15, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = normals[knns]\n",
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87916d9f-f056-4aa2-a2b3-b88f853aedb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the transpose matrix\n",
    "Nt = N.transpose(0, 2, 1)\n",
    "Nt.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30febc25-9a2f-4b72-99cd-63aefcde9b40",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de892f52-a425-4af0-977b-6b52f05052c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = np.matmul(Nt, N)\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cefacac-d72e-4e57-9718-f6a6727f5ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not that the operant '*' is not used for matrix multiplication in numpy\n",
    "cov = Nt @ N\n",
    "cov.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50099ccf-4b6a-463f-97b5-38fa2f962d11",
   "metadata": {},
   "source": [
    "### Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5412f49b-34c2-4eab-aa8a-c8477f6a3bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = np.einsum('bik, bkj -> bij', Nt, N)\n",
    "cov.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a429b59-5137-4be2-abb7-5aefd240ce99",
   "metadata": {},
   "source": [
    "## Eigen decomposition on the whole covariance matrix\n",
    "\n",
    "This is done the same as before. Numpy knows that in order to decompose a matrix it has to be square, so when given an array of shape [N, 3, 3] it knows there are N square matrices of shape 3x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abe7aef7-5ca6-4e5e-b1c4-2ba2eafabb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues, _ = np.linalg.eig(cov) \n",
    "eigenvalues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9396db19-a2d4-4964-a761-71517f2e19d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33910,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saliency = 1 / np.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "saliency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2444580d-4992-4fea-8520-0952503d140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "visualize_saliency(mesh, saliency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85d130ce-aa34-4be4-832d-a2506018f4a2",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c164619-ac66-4f6d-ab83-b49055bc9ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_numpy(normals, knns):\n",
    "    N = normals[knns]\n",
    "    Nt = N.transpose(0, 2, 1)\n",
    "    cov = Nt @ N\n",
    "    eigenvalues, _ = np.linalg.eig(cov) \n",
    "    saliency = 1 / np.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "701fffac-63d3-42d8-b02c-53db97b6fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.5 ms ± 1.46 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_numpy(normals, knns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16e3a031-0f0c-418a-9476-fed7e38e3e0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Torch saliency calculation\n",
    "\n",
    "PyTorch is one of the main libraries used in Deep Learning. We will try to use pytorch instead of numpy. \n",
    "\n",
    "Instead on numpy arrays we use torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72bead7a-418f-493f-a05e-5215b55dbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# torch.tensor() can cast a numpy array to a torch tensor\n",
    "normals_t = torch.tensor(normals)\n",
    "knns_t = torch.tensor(knns).long()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc526d9d-039a-44fb-a977-2e84169a8aa8",
   "metadata": {},
   "source": [
    "Indexing in PyTorch is similar to numpy, so to create the **N** matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "753169d5-044e-4ea6-85ba-059b5a285ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = normals_t[knns_t]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93069dc2-6e86-4cf7-807c-9ecf9f1807d1",
   "metadata": {},
   "source": [
    "Next we need to create the inverse of the **N** matrix, **Nt**. *torch.permute* has a similar functionality as np.transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8aa431ac-5f87-4847-8522-7359c156f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nt = N.permute(0, 2, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82ae8532-42c8-444e-9110-bda4b8259d1b",
   "metadata": {},
   "source": [
    "The covariance matrix and the eigen decomposition is similar to numpy. Again we have to replace the numpy specific methods with the corresponding ones of pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bae0692-4863-49b2-ba93-2a13d561d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the covariance matrix\n",
    "cov = Nt @ N\n",
    "# Perform eigen decomposition\n",
    "eigenvalues = torch.linalg.eigvals(cov).real # torch calculates complex eigenvalues so we have to keep the real part\n",
    "# Calculate the saliency values\n",
    "saliency = 1 / np.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "# Normalize the values in range(0,1) for visualization\n",
    "saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "# Visualize the result\n",
    "visualize_saliency(mesh, saliency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66492d46-16ae-44bd-8832-a5f62c5c6b14",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19fc5263-cc66-4f29-88b7-e30436000a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_torch(normals, knns):\n",
    "    normals_t = torch.tensor(normals)\n",
    "    knns_t = torch.tensor(knns).long()\n",
    "    \n",
    "    N = normals_t[knns_t]\n",
    "    Nt = N.permute(0, 2, 1)\n",
    "    \n",
    "    cov = Nt @ N\n",
    "    eigenvalues = torch.linalg.eigvals(cov).real # torch calculates complex eigenvalues so we have to keep the real part\n",
    "    \n",
    "    saliency = 1 / torch.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "    \n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6bf6dd69-84d0-43d0-862f-18ce54df32d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.8 ms ± 565 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_torch(normals, knns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "460ac098-a27f-4af9-bf09-fcbafb2a76b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Torch CUDA (GPU) saliency calculation\n",
    "\n",
    "PyTorch gives you the ability to easily do the calculations on the GPU simply by transfering the data to the GPU.\n",
    "\n",
    "Every tensor in PyTorch has an attribute called device. If the device is *cpu* then the tensor is located in the CPU. When the tensor is located on the GPU, the device name will not be *gpu*. Instead it will be something like *cuda:0*. CUDA is a library developed by NVIDIA to write code to run on NVIDIA gpus. Since only NVIDIA GPUs are supported by PyTorch it uses the keyword cuda instead of gpu. The number after the : indicates the number of the GPU, using zero indexing. \n",
    "\n",
    "It is important to note, that in order to do any operation between two tensors, they must be on the same device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0a37ef90-0022-4b46-9a96-04ceccfdc8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'normals_t' is located in the cpu || 'normals_t_gpu' is located in the cuda:0\n"
     ]
    }
   ],
   "source": [
    "normlas_t_gpu = normals_t.cuda()\n",
    "knns_t_gpu = knns_t.cuda()\n",
    "\n",
    "print(f\"'normals_t' is located in the {normals_t.device} || 'normals_t_gpu' is located in the {normlas_t_gpu.device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5d8d8ea-4385-4b1d-8ae4-2949374ab571",
   "metadata": {},
   "source": [
    "The rest of the PyTorch code remains the same no matter the device that we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b87afb29-7445-45e7-94c1-d511ec78b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = normlas_t_gpu[knns_t_gpu]\n",
    "Nt = N.permute(0, 2, 1)\n",
    "\n",
    "cov = Nt @ N        \n",
    "eigenvalues = torch.linalg.eigvals(cov).real # torch calculates complex eigenvalues so we have to keep the real part\n",
    "\n",
    "saliency = 1 / torch.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12bb5ee3-792b-4faf-b75e-b191f0ef4c4a",
   "metadata": {},
   "source": [
    "In we want to use a tensor outside PyTorch, for example turn it back to numpy, we have to first move it to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efbaf365-2405-4b03-bf3d-866bbba30414",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency = saliency.cpu().numpy()\n",
    "visualize_saliency(mesh, saliency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7463a35-0267-45ed-b324-db64c4fc0eeb",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3690c43d-b964-44fa-8ab0-270b1b1aeeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_torch_cuda(normals, knns):\n",
    "    normals_t = torch.tensor(normals).cuda()\n",
    "    knns_t = torch.tensor(knns).long().cuda()\n",
    "    \n",
    "    N = normals_t[knns_t]\n",
    "    Nt = N.permute(0, 2, 1)\n",
    "    cov = Nt @ N\n",
    "    \n",
    "    eigenvalues = torch.linalg.eigvals(cov).real # torch calculates complex eigenvalues so we have to keep the real part\n",
    "    saliency = 1 / torch.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "    \n",
    "    return saliency.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9bb14a2-dc16-4257-89c3-7957bc5cd31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.5 ms ± 1.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_torch_cuda(normals, knns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f4e4060-0f65-48eb-8c5c-eb23e9815bfa",
   "metadata": {},
   "source": [
    "## Transfer data to GPU only once\n",
    "\n",
    "Copying the data of a tensor from the CPU to the GPU, and vise versa, takes some time. Usually, we use the GPU to do heavy operations. Because saliency calculation is not such a demanding task, moving the data back and forth between the CPU and the GPU takes a relatively considerable amount of time. \n",
    "\n",
    "To demonstrate the efficiency of the GPU, we will create a function that operates on data already on the GPU and will not ask it to return the data to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c1624aee-d23b-4e87-8026-af46d12a6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_torch_cuda_once(normals_t, knns_t):\n",
    "    N = normals_t[knns_t]\n",
    "    Nt = N.permute(0, 2, 1)\n",
    "    cov = Nt @ N\n",
    "    \n",
    "    eigenvalues = torch.linalg.eigvals(cov).real # torch calculates complex eigenvalues so we have to keep the real part\n",
    "    saliency = 1 / torch.sqrt(eigenvalues[:, 0] * eigenvalues[:, 0] + eigenvalues[:, 1] * eigenvalues[:, 1] + eigenvalues[:, 2] * eigenvalues[:, 2])\n",
    "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
    "    \n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "049ca862-58a1-43e8-b8cf-51bd43afa0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "normals_t = torch.tensor(normals).cuda()\n",
    "knns_t = torch.tensor(knns).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f78c2f0a-8eb3-481f-9b9a-1026a77a1673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.4 ms ± 800 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=saliency_torch_cuda_once(normals_t, knns_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37f8d016-2872-4082-a8b5-555af81aba5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fast KNN computation\n",
    "\n",
    "We notice that the computation time of saliency is around 20ms (This time may differ depending on the machine that you are using). \n",
    "However, if we go back and see the KNN calculation time, it is 125 ms, that is more than 6 times slower. \n",
    "\n",
    "Thankfully, Open3D provides a faster way to compute the KNNs for a whole mesh at once. \n",
    "The reason I did not introduce it earlier was because it operates on torch tensors and I wanted to make a smooth introduction to torch first. This method is a part of the Open3D ml library that is install along with Open3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08d04627-e180-43fb-ae2e-cfbd7aa2360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d.ml.torch as ml3d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "441b9c59-d16f-4d11-8fbf-efb925d8943c",
   "metadata": {},
   "source": [
    "We want to create a point cloud, containing the vertices of the original mesh, and store it as a torch.tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5f708e4-ed09-472a-a214-d0c9f9dc9f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33910, 3]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "vertices = np.asarray(mesh.vertices)\n",
    "pc = torch.tensor(vertices)\n",
    "print(pc.shape, type(pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "07527ab7-af63-4ef5-acea-bc6a749d6f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33910, 15])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=15\n",
    "nsearch = ml3d.layers.KNNSearch()\n",
    "# nsearch(target_points, query_points, number_of_neighbors)\n",
    "ans = nsearch(pc, pc, k)\n",
    "\n",
    "# this method returns among other information the neighbors_index\n",
    "neighbors_index = ans.neighbors_index.reshape(pc.shape[0], -1) # Note that we have to reshape the result\n",
    "neighbors_index.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e2fd23-2f79-48b6-a340-af0f2a5a8de3",
   "metadata": {},
   "source": [
    "### Let's test that we get the expected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3d68920-1d76-4b46-9605-9cdbf85fbb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_87333/84531162.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  knns_t = torch.tensor(knns).long()\n"
     ]
    }
   ],
   "source": [
    "saliency = saliency_torch(normals, neighbors_index)\n",
    "visualize_saliency(mesh, saliency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7bdc3c7-f0f2-45cc-a964-1c7a44a9035b",
   "metadata": {},
   "source": [
    "## Let's wrap up everything into a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c7eba14-9a65-42fb-b614-626c5f65253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_search_fast(mesh, k): # use same inputs as before\n",
    "    nsearch = ml3d.layers.KNNSearch()\n",
    "    ans = nsearch(pc, pc, k)\n",
    "    neighbors_index = ans.neighbors_index.reshape(pc.shape[0], -1)\n",
    "    return neighbors_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d1d0545d-b06e-4323-9c3e-90dee10dabb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75 ms ± 573 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n10 _=knn_search_fast(mesh, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9377669-e1fe-4808-984d-9db08b3393b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44cde300-9ba3-45d2-a3ae-06f552bed308",
   "metadata": {},
   "source": [
    "# Homework:\n",
    "\n",
    "## 1. Test the topology of the mesh to validate the KNN neighbors.\n",
    "The KNN search may return neighbors that are near the query point in the euclidean space, but may be topologicaly very far. \n",
    "Let's take for example a human model that is scratching his head. A point on the head of the model may be close to a point of the arm in terms of euclidean distance but topologically the distance is very large. \n",
    "So in this task set a topological distance threshold and make sure all the neighbors are withing this limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fba45-09cf-4026-a307-20d65b0b023e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
